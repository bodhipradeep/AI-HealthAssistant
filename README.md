# ğŸ¥ AI Health Assistant

AI Health Assistant is an experimental multi-agent medical reasoning system that accepts patient symptoms and optional report PDFs, runs a LangGraph-powered agent workflow, and returns structured diagnostic reasoning plus a recommended treatment plan. The system is intended for research and human-in-the-loop experimentation and is not a substitute for professional medical care.

## Tech used
- Python 3.11+
- FastAPI (backend)
- Streamlit (front-end)
- Speech AI (Audio output)
- LangGraph (workflow & HITL) 
- LangChain / Transformers (LLM adapters)
- Unsloth QLoRA (For Fine-Tuned 2x faster)
- Docker for containerization

---
## Output Screenshot
<img width="1679" height="915" alt="Screenshot 2025-08-24 183419" src="https://github.com/user-attachments/assets/70f50ee8-4006-4824-9044-cfb69e8bbdd9" />

---
## ğŸ“Œ Features
- **Fine-tuned BioMistral-7B** using [Unsloth QLoRA](https://huggingface.co/unsloth) for domain-specific medical reasoning
- **Input** Pateint details, symptoms, report(optional), weather info automatic use if needed 
- **LangGraph Human-in-the-loop cycle** for reasoning with human validation
- **Multi-node LangGraph workflow:** symptom analysis â†’ generated symptoms â†’ patient confirmation (HITL) â†’ diagnosis â†’ treatment plan
- **Disease detection** from symptoms + structured report data
- **Medical advisory recommendations** (non-diagnostic, informational only)
- **FastAPI backend** + **Streamlit frontend**
# AI Health Assistant

---
## ğŸ“‚ Dataset & Model
- **Dataset:** [Clinical Dataset on Hugging Face](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT)
- **Base Model** [[BioMistral-7B Base Model](https://huggingface.co/BioMistral/BioMistral-7B)
- **QLoRA Adapter:** [[BioMistral-7B QLoRA Adapter](https://huggingface.co/PradeepBodhi/BioMistral-7b_Fine-Tuned-QLoRA)
- **Full Fine-Tuned** [[BioMistral-7B QLoRA Adapter + Base Model](https://huggingface.co/PradeepBodhi/BioMistral-7b_Fine-Tuned-FULL)

---
## Project structure

AI-HealthAssistant/
â”œâ”€â”€ Dockerfile                # Docker container definition (runs uvicorn fastapi_app:app)
â”œâ”€â”€ docker-compose.yml        # Example compose file
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ pyproject.toml            # Project metadata
â”œâ”€â”€ main.py                   # Simple local entry/test script
â”œâ”€â”€ main_st.py                # Streamlit UI client
â”œâ”€â”€ fastapi_app.py            # FastAPI backend (endpoints and session handling)
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main_page.png         # Empty UI Screenshot
â”‚   â”œâ”€â”€ output.png            # Output UI Screenshot
â”‚   â””â”€â”€ image.png             # Langgrpah Flow image
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ diagnosis.py          # diagnosis logic (model prompt + invocation)
â”‚   â”œâ”€â”€ gen_symptoms.py       # generate/refine symptoms
â”‚   â”œâ”€â”€ sym_analyzer.py       # symptom analysis
â”‚   â””â”€â”€ treatment_plan.py     # produce treatment plan from diagnosis
â”œâ”€â”€ workflow/
â”‚   â”œâ”€â”€ graph_builder.py      # LangGraph StateGraph definition and compilation
â”‚   â”œâ”€â”€ agent_nodes.py        # node wrappers that call agent functions
â”‚   â”œâ”€â”€ append_symptoms.py    # append new symptoms from HITL
â”‚   â””â”€â”€ hitl.py               # human-in-the-loop helpers
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml           # LLM/provider configuration
â”‚   â””â”€â”€ settings.py           # other settings
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ report_loader.py      # PDF extraction helper
â”‚   â””â”€â”€ weather_info.py       # optional weather enrichment
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ model_loader.py       # Fine-Tuned LLM/model initialization and selection
â”‚   â””â”€â”€ config_loader.py
â””â”€â”€ .env.example              # .env file for api key requirement

--- 
## ğŸ³ Docker Deployment

Build and run locally:

```powershell
; docker build -t ai-healthassistant .
; docker run -p 8000:8000 --env-file .env ai-healthassistant
```

Using docker-compose:

```powershell
; docker-compose up --build
```

## ğŸ“¦ Pull from Docker Hub
If you prefer, you can pull the pre-built image from Docker Hub:

```bash
# Pull docker file
docker pull bodhipradeep/ai-health-assistant

# Run docker file
docker run -p 8000:8000 --env-file .env bodhipradeep/ai-health-assistant
```
---
## How it works (detailed flow â€” based on `workflow/graph_builder.py`)

The LangGraph state graph composes the multi-agent reasoning pipeline as follows:

1. Symptoms_Analysis (node_symptoms_analysis)
2. Generated_Symptoms (node_generated_symptoms)
3. Patient_Confirmation (human_assistance)
4. Conditional branching (human_decision)
5. Need_More_Symptoms (append_symptoms.add_symptoms)
6. Diagnosis (node_diagnosis)
7. Final_Report (node_treatment_plan)
8. End: the graph returns the aggregated messages and final plan to the API caller.

---
## API (quick reference)

- POST `/diagnose/start` â€” start a new session
  - JSON: `{ "symptoms": [...], "patient_details": {...}, "report": "optional text" }`
  - Returns: `{ "thread_id": "...", "symptoms": [...], "result": "..." }`

- POST `/diagnosis/resume` â€” resume a session from the UI or via API
  - JSON: `{ "thread_id": "...", "human": "feedback" | "approved", "more_symptoms": [...] }`

---
## Disclaimer

This project is research/educational only and does not provide medical advice. Always consult a licensed healthcare professional for diagnosis and treatment.

## License

MIT License Â© 2025 Pradeep Kumar

## Author / Contact

Pradeep Kumar

- LinkedIn: [Pradeep Kumar](https://www.linkedin.com/in/bodhi-pradeep/)  
- Email: [Gmail](mailto:pradeep.kmr.pro@gmail.com)




